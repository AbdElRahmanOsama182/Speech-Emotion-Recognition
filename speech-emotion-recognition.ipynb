{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pattern Recognition: Speech Emotion Recognition\n",
    "**Team Members:**\n",
    "- AbdElRahman Bassam\n",
    "- AbdElRahman Osama\n",
    "- Ahmed Youssef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T06:52:40.768416Z",
     "iopub.status.busy": "2025-05-15T06:52:40.768159Z",
     "iopub.status.idle": "2025-05-15T06:52:47.996426Z",
     "shell.execute_reply": "2025-05-15T06:52:47.995647Z",
     "shell.execute_reply.started": "2025-05-15T06:52:40.768394Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "import os\n",
    "import math\n",
    "import IPython.display as ipd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "import glob\n",
    "import itertools\n",
    "import json\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T06:52:47.997975Z",
     "iopub.status.busy": "2025-05-15T06:52:47.997550Z",
     "iopub.status.idle": "2025-05-15T06:52:48.002490Z",
     "shell.execute_reply": "2025-05-15T06:52:48.001806Z",
     "shell.execute_reply.started": "2025-05-15T06:52:47.997949Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "CREMA_PATH = '../input/speech-emotion-recognition-en/Crema/'\n",
    "\n",
    "EMOTION_MAPPING = {\n",
    "    \"SAD\" : \"sadness\",\n",
    "    \"ANG\" : \"angry\",\n",
    "    \"DIS\" : \"disgust\",\n",
    "    \"FEA\" : \"fear\",\n",
    "    \"HAP\" : \"happy\",\n",
    "    \"NEU\" : \"neutral\"\n",
    "}\n",
    "\n",
    "female_ids = [1002,1003,1004,1006,1007,1008,1009,1010,1012,1013,1018,1020,1021,\n",
    "              1024,1025,1028,1029,1030,1037,1043,1046,1047,1049,1052,1053,1054,\n",
    "              1055,1056,1058,1060,1061,1063,1072,1073,1074,1075,1076,1078,1079,\n",
    "              1082,1084,1089,1091]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T06:52:48.003480Z",
     "iopub.status.busy": "2025-05-15T06:52:48.003232Z",
     "iopub.status.idle": "2025-05-15T06:52:48.015436Z",
     "shell.execute_reply": "2025-05-15T06:52:48.014910Z",
     "shell.execute_reply.started": "2025-05-15T06:52:48.003464Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# load audio from path, with sr as default=16KHz (to resample the audio to unique sr)\n",
    "def load_audio(path, sr=16000):\n",
    "  audio, sr = librosa.load(path, sr=sr)\n",
    "  return audio, sr\n",
    "\n",
    "def get_emotion_from_filename(filename):\n",
    "  return EMOTION_MAPPING.get(filename.split(\"_\")[2])\n",
    "\n",
    "def get_gender_from_filename(filename):\n",
    "    actor_id = int(filename.split(\"_\")[0])  # Assuming the actor ID is the first part of the filename\n",
    "    return 'female' if actor_id in female_ids else 'male'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T06:52:48.017330Z",
     "iopub.status.busy": "2025-05-15T06:52:48.017086Z",
     "iopub.status.idle": "2025-05-15T06:52:48.027345Z",
     "shell.execute_reply": "2025-05-15T06:52:48.026824Z",
     "shell.execute_reply.started": "2025-05-15T06:52:48.017314Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def explore_audio(audio_path):\n",
    "    filename = os.path.basename(audio_path)\n",
    "    print(f\"\\nExploring: {filename}\")\n",
    "    audio, sr = load_audio(path=audio_path, sr=None)\n",
    "    ipd.display(ipd.Audio(audio, rate=sr))\n",
    "    plt.figure(figsize=(10, 3))\n",
    "    librosa.display.waveshow(audio, sr=sr)\n",
    "    plt.suptitle(f\"Waveform - {filename}\")\n",
    "    plt.title(f\"Emotion: {get_emotion_from_filename(filename)}\")\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def explore_dataset(dataset_path):\n",
    "  emotions_visited = set()\n",
    "  one_sample_per_emotion = {}\n",
    "\n",
    "  for filename in os.listdir(dataset_path):\n",
    "    if filename.endswith(\".wav\"):\n",
    "      emotion = get_emotion_from_filename(filename)\n",
    "      if emotion in emotions_visited:\n",
    "        continue\n",
    "      one_sample_per_emotion[emotion] = os.path.join(dataset_path, filename)\n",
    "      emotions_visited.add(emotion)\n",
    "      if len(emotions_visited) == len(EMOTION_MAPPING):\n",
    "        break\n",
    "\n",
    "  for emotion, path in one_sample_per_emotion.items():\n",
    "    print(f\"\\nEmotion: {emotion}\")\n",
    "    explore_audio(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T06:52:48.028264Z",
     "iopub.status.busy": "2025-05-15T06:52:48.028052Z",
     "iopub.status.idle": "2025-05-15T06:53:01.931697Z",
     "shell.execute_reply": "2025-05-15T06:53:01.930957Z",
     "shell.execute_reply.started": "2025-05-15T06:52:48.028241Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "explore_dataset(CREMA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Feature Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T06:53:01.932802Z",
     "iopub.status.busy": "2025-05-15T06:53:01.932399Z",
     "iopub.status.idle": "2025-05-15T06:53:01.941679Z",
     "shell.execute_reply": "2025-05-15T06:53:01.940867Z",
     "shell.execute_reply.started": "2025-05-15T06:53:01.932771Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Extract zero-crossing-rate sequence\n",
    "def extract_zcr_seq(y, frame_length=2048, hop_length=512):\n",
    "    zcr_seq = librosa.feature.zero_crossing_rate(y, frame_length=frame_length, hop_length=hop_length)[0]\n",
    "    return zcr_seq\n",
    "\n",
    "# Extract Root Mean Square sequence\n",
    "def extract_rms_seq(y, frame_length=2048, hop_length=512):\n",
    "    rms_seq = librosa.feature.rms(y=y, frame_length=frame_length, hop_length=hop_length)[0]\n",
    "    return rms_seq\n",
    "\n",
    "# Extract Mel Spectrogram with 128 Mel bands\n",
    "def extract_mel_spectrogram(y, sr, n_mels=128, frame_length=2048, hop_length=512):\n",
    "    mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=frame_length, hop_length=hop_length, n_mels=n_mels)\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec)\n",
    "    return mel_spec_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T06:53:01.943086Z",
     "iopub.status.busy": "2025-05-15T06:53:01.942753Z",
     "iopub.status.idle": "2025-05-15T06:54:10.424673Z",
     "shell.execute_reply": "2025-05-15T06:54:10.423956Z",
     "shell.execute_reply.started": "2025-05-15T06:53:01.943056Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# X_zcr = [] # zero-crossing-rate\n",
    "# X_rms = [] # RMS\n",
    "# X_mel = [] # mel spectogram data\n",
    "y = [] # labels\n",
    "y_gender = [] # labels consedring the gender\n",
    "mx_audio_len = 0\n",
    "# find max audio len\n",
    "for filename in os.listdir(CREMA_PATH):\n",
    "  if filename.endswith(\".wav\"):\n",
    "    filepath = os.path.join(CREMA_PATH, filename)\n",
    "    audio, _ = load_audio(filepath)\n",
    "    mx_audio_len = max(mx_audio_len,len(audio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T06:54:10.426197Z",
     "iopub.status.busy": "2025-05-15T06:54:10.425927Z",
     "iopub.status.idle": "2025-05-15T06:54:10.430417Z",
     "shell.execute_reply": "2025-05-15T06:54:10.429751Z",
     "shell.execute_reply.started": "2025-05-15T06:54:10.426174Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# for filename in sorted(os.listdir(CREMA_PATH)):\n",
    "#   if filename.endswith(\".wav\"):\n",
    "#     filepath = os.path.join(CREMA_PATH, filename)\n",
    "#     audio, sr = load_audio(filepath)\n",
    "#     # pad center the audio so all have same length\n",
    "#     audio = librosa.util.pad_center(audio, size=mx_audio_len)\n",
    "#     X_zcr.append(extract_zcr_seq(audio))\n",
    "#     X_rms.append(extract_rms_seq(audio))\n",
    "#     X_mel.append(extract_mel_spectrogram(audio, sr))\n",
    "#     emotion = get_emotion_from_filename(filepath)\n",
    "#     gender = get_gender_from_filename(filename)\n",
    "#     y.append(emotion)\n",
    "#     y_gender.append(f\"{emotion}_{gender}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T06:54:10.432080Z",
     "iopub.status.busy": "2025-05-15T06:54:10.431303Z",
     "iopub.status.idle": "2025-05-15T06:58:05.349019Z",
     "shell.execute_reply": "2025-05-15T06:58:05.348252Z",
     "shell.execute_reply.started": "2025-05-15T06:54:10.432046Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "CACHE_DIR = \"/kaggle/working/saved_features\"\n",
    "os.makedirs(CACHE_DIR, exist_ok=True)\n",
    "\n",
    "X_zcr, X_rms, X_mel, y, y_gender = [], [], [], [], []\n",
    "\n",
    "for filename in sorted(os.listdir(CREMA_PATH)):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        cache_path = os.path.join(CACHE_DIR, f\"{filename}.npz\")\n",
    "\n",
    "        if os.path.exists(cache_path):\n",
    "            data = np.load(cache_path)\n",
    "            zcr, rms, mel = data['zcr'], data['rms'], data['mel']\n",
    "        else:\n",
    "            filepath = os.path.join(CREMA_PATH, filename)\n",
    "            audio, sr = load_audio(filepath)\n",
    "            audio = librosa.util.pad_center(audio, size=mx_audio_len)\n",
    "            zcr = extract_zcr_seq(audio)\n",
    "            rms = extract_rms_seq(audio)\n",
    "            mel = extract_mel_spectrogram(audio, sr)\n",
    "            np.savez(cache_path, zcr=zcr, rms=rms, mel=mel)\n",
    "\n",
    "        X_zcr.append(zcr)\n",
    "        X_rms.append(rms)\n",
    "        X_mel.append(mel)\n",
    "\n",
    "        emotion = get_emotion_from_filename(filename)\n",
    "        gender = get_gender_from_filename(filename)\n",
    "        y.append(emotion)\n",
    "        y_gender.append(f\"{emotion}_{gender}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T06:58:05.352326Z",
     "iopub.status.busy": "2025-05-15T06:58:05.351879Z",
     "iopub.status.idle": "2025-05-15T06:58:05.563421Z",
     "shell.execute_reply": "2025-05-15T06:58:05.562695Z",
     "shell.execute_reply.started": "2025-05-15T06:58:05.352299Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_zcr = np.array(X_zcr)\n",
    "X_energy = np.array(X_rms)\n",
    "X_mel = np.array(X_mel)\n",
    "y = np.array(y)\n",
    "y_gender = np.array(y_gender)\n",
    "print(np.shape(X_zcr))\n",
    "print(np.shape(X_rms))\n",
    "print(np.shape(X_mel))\n",
    "print(np.shape(y))\n",
    "print(np.shape(y_gender))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T06:58:05.564492Z",
     "iopub.status.busy": "2025-05-15T06:58:05.564247Z",
     "iopub.status.idle": "2025-05-15T06:58:07.146397Z",
     "shell.execute_reply": "2025-05-15T06:58:07.145628Z",
     "shell.execute_reply.started": "2025-05-15T06:58:05.564473Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# visualize 3 random samples in feature spaces\n",
    "np.random.seed(RANDOM_SEED)\n",
    "indices = np.random.choice(X_mel.shape[0], size=3, replace=False)\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "# Plot mel spectograms\n",
    "for i, idx in enumerate(indices):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    librosa.display.specshow(X_mel[idx], sr=16000, x_axis='time', y_axis='mel')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title(f\"Sample #{idx}\")\n",
    "\n",
    "# Plot RMSE\n",
    "for i, idx in enumerate(indices):\n",
    "    plt.subplot(3, 3, i+4)\n",
    "    plt.plot(X_rms[idx])\n",
    "    plt.title(f\"RMSE - Sample #{idx}\")\n",
    "    plt.xlabel(\"Frame\")\n",
    "    plt.ylabel(\"RMSE\")\n",
    "\n",
    "# Plot ZCR\n",
    "for i, idx in enumerate(indices):\n",
    "    plt.subplot(3, 3, i+7)\n",
    "    plt.plot(X_zcr[idx])\n",
    "    plt.title(f\"ZCR - Sample #{idx}\")\n",
    "    plt.xlabel(\"Frame\")\n",
    "    plt.ylabel(\"ZCR\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T06:58:07.147492Z",
     "iopub.status.busy": "2025-05-15T06:58:07.147273Z",
     "iopub.status.idle": "2025-05-15T06:58:07.525706Z",
     "shell.execute_reply": "2025-05-15T06:58:07.524932Z",
     "shell.execute_reply.started": "2025-05-15T06:58:07.147476Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Plotting class frequencies\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "class_counts = np.unique(y, return_counts=True)\n",
    "sns.barplot(x=class_counts[0], y=class_counts[1])\n",
    "\n",
    "plt.title('Class Frequency Distribution')\n",
    "plt.xlabel('Emotion Classes')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T06:58:07.526797Z",
     "iopub.status.busy": "2025-05-15T06:58:07.526495Z",
     "iopub.status.idle": "2025-05-15T06:58:07.727236Z",
     "shell.execute_reply": "2025-05-15T06:58:07.726420Z",
     "shell.execute_reply.started": "2025-05-15T06:58:07.526773Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Plotting class frequencies\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "class_counts = np.unique(y_gender, return_counts=True)\n",
    "sns.barplot(x=class_counts[0], y=class_counts[1])\n",
    "\n",
    "plt.title('Class Frequency Distribution Consedring Gender)')\n",
    "plt.xlabel('Emotion_Gender Classes')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T06:58:07.728112Z",
     "iopub.status.busy": "2025-05-15T06:58:07.727898Z",
     "iopub.status.idle": "2025-05-15T06:58:07.744018Z",
     "shell.execute_reply": "2025-05-15T06:58:07.743363Z",
     "shell.execute_reply.started": "2025-05-15T06:58:07.728097Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_time = np.stack([X_zcr, X_rms], axis=1) # stack time features in to one feature space\n",
    "print(X_time.shape)\n",
    "# Add channel dimension at axis=1 -> shape becomes (7442, 1, 128, 157)\n",
    "X_mel = X_mel[:, np.newaxis, :, :]\n",
    "print(X_mel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T06:58:07.745049Z",
     "iopub.status.busy": "2025-05-15T06:58:07.744844Z",
     "iopub.status.idle": "2025-05-15T06:58:07.751163Z",
     "shell.execute_reply": "2025-05-15T06:58:07.750431Z",
     "shell.execute_reply.started": "2025-05-15T06:58:07.745033Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def split_data(X_time, X_mel, y, y_gender, test_size=0.3, val_size=0.05, random_state=42):\n",
    "    # First split into train+val and test\n",
    "    idx_trainval, idx_test = train_test_split(\n",
    "        np.arange(len(y)), stratify=y, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "\n",
    "    # Then split train+val into train and val\n",
    "    y_trainval = y[idx_trainval]\n",
    "    idx_train, idx_val = train_test_split(\n",
    "        idx_trainval, stratify=y_trainval, test_size=val_size, random_state=random_state\n",
    "    )\n",
    "\n",
    "    # Use indices to slice all arrays\n",
    "    def split_arrays(arr):\n",
    "        return arr[idx_train], arr[idx_val], arr[idx_test]\n",
    "\n",
    "    X_time_train, X_time_val, X_time_test = split_arrays(X_time)\n",
    "    X_mel_train, X_mel_val, X_mel_test = split_arrays(X_mel)\n",
    "    y_train, y_val, y_test = split_arrays(y)\n",
    "    y_gender_train, y_gender_val, y_gender_test = split_arrays(y_gender)\n",
    "\n",
    "    return (X_time_train, X_time_val, X_time_test,\n",
    "            X_mel_train, X_mel_val, X_mel_test,\n",
    "            y_train, y_val, y_test,\n",
    "            y_gender_train, y_gender_val, y_gender_test,\n",
    "            idx_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T06:58:07.752210Z",
     "iopub.status.busy": "2025-05-15T06:58:07.751919Z",
     "iopub.status.idle": "2025-05-15T06:58:07.952515Z",
     "shell.execute_reply": "2025-05-15T06:58:07.951937Z",
     "shell.execute_reply.started": "2025-05-15T06:58:07.752186Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "(X_time_train, X_time_val, X_time_test,\n",
    " X_mel_train, X_mel_val, X_mel_test,\n",
    " y_train, y_val, y_test,\n",
    " y_train_g, y_val_g, y_test_g, idx_train) = split_data(X_time, X_mel, y, y_gender)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T06:58:07.953318Z",
     "iopub.status.busy": "2025-05-15T06:58:07.953119Z",
     "iopub.status.idle": "2025-05-15T06:58:07.975883Z",
     "shell.execute_reply": "2025-05-15T06:58:07.975372Z",
     "shell.execute_reply.started": "2025-05-15T06:58:07.953302Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_set_names = np.array(sorted(glob.glob(os.path.join(CREMA_PATH, \"*.wav\"))))[idx_train]\n",
    "sample_audio_path = train_set_names[0]\n",
    "sample_audio, sr = load_audio(sample_audio_path,16000)\n",
    "sample_audio = librosa.util.pad_center(sample_audio, size=mx_audio_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T06:58:07.976806Z",
     "iopub.status.busy": "2025-05-15T06:58:07.976536Z",
     "iopub.status.idle": "2025-05-15T06:58:07.981277Z",
     "shell.execute_reply": "2025-05-15T06:58:07.980706Z",
     "shell.execute_reply.started": "2025-05-15T06:58:07.976779Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def noise(data):\n",
    "    noise_amp = 0.035*np.random.uniform()*np.amax(data)\n",
    "    data = data + noise_amp*np.random.normal(size=data.shape[0])\n",
    "    return data\n",
    "\n",
    "def shift(data):\n",
    "    shift_range = int(np.random.uniform(low=-5, high = 5)*1000)\n",
    "    return np.roll(data, shift_range)\n",
    "\n",
    "def pitch(data, sr, n_steps=-1):\n",
    "    return librosa.effects.pitch_shift(y=data, sr=sr, n_steps=n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T06:58:07.982252Z",
     "iopub.status.busy": "2025-05-15T06:58:07.981952Z",
     "iopub.status.idle": "2025-05-15T06:58:08.308023Z",
     "shell.execute_reply": "2025-05-15T06:58:08.307296Z",
     "shell.execute_reply.started": "2025-05-15T06:58:07.982230Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Original Audio\")\n",
    "ipd.display(ipd.Audio(sample_audio, rate=sr))\n",
    "plt.figure(figsize=(14, 4))\n",
    "librosa.display.waveshow(sample_audio, sr=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T06:58:08.309227Z",
     "iopub.status.busy": "2025-05-15T06:58:08.308943Z",
     "iopub.status.idle": "2025-05-15T06:58:08.694385Z",
     "shell.execute_reply": "2025-05-15T06:58:08.693643Z",
     "shell.execute_reply.started": "2025-05-15T06:58:08.309204Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"With Noise Audio\")\n",
    "aug = noise(sample_audio)\n",
    "ipd.display(ipd.Audio(aug, rate=sr))\n",
    "plt.figure(figsize=(14, 4))\n",
    "librosa.display.waveshow(aug, sr=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T06:58:08.695203Z",
     "iopub.status.busy": "2025-05-15T06:58:08.695013Z",
     "iopub.status.idle": "2025-05-15T06:58:09.838949Z",
     "shell.execute_reply": "2025-05-15T06:58:09.838225Z",
     "shell.execute_reply.started": "2025-05-15T06:58:08.695189Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"With Lower Pitch Audio\")\n",
    "aug = pitch(sample_audio,sr)\n",
    "ipd.display(ipd.Audio(aug, rate=sr))\n",
    "plt.figure(figsize=(14, 4))\n",
    "librosa.display.waveshow(aug, sr=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T06:58:09.839994Z",
     "iopub.status.busy": "2025-05-15T06:58:09.839791Z",
     "iopub.status.idle": "2025-05-15T06:58:10.157674Z",
     "shell.execute_reply": "2025-05-15T06:58:10.156873Z",
     "shell.execute_reply.started": "2025-05-15T06:58:09.839978Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Shifted Audio\")\n",
    "aug = shift(sample_audio)\n",
    "ipd.display(ipd.Audio(aug, rate=sr))\n",
    "plt.figure(figsize=(14, 4))\n",
    "librosa.display.waveshow(aug, sr=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T06:58:10.159257Z",
     "iopub.status.busy": "2025-05-15T06:58:10.158628Z",
     "iopub.status.idle": "2025-05-15T06:58:10.164926Z",
     "shell.execute_reply": "2025-05-15T06:58:10.164260Z",
     "shell.execute_reply.started": "2025-05-15T06:58:10.159237Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def augment(audio,sr):\n",
    "    return noise(audio), pitch(audio,sr), shift(audio)\n",
    "\n",
    "is_augmented = False\n",
    "if is_augmented:\n",
    "    aug_X_time = []\n",
    "    aug_X_mel = []\n",
    "    aug_y = []\n",
    "    aug_y_gender = []\n",
    "    for path in train_set_names:\n",
    "        filename = os.path.basename(path)\n",
    "        audio,sr = load_audio(path)\n",
    "        audio = librosa.util.pad_center(sample_audio, size=mx_audio_len)\n",
    "        np.random.seed(RANDOM_SEED)\n",
    "        audio_noise, audio_pitch, audio_shift = augment(audio, sr)\n",
    "        emotion = get_emotion_from_filename(filename)\n",
    "        gender = get_gender_from_filename(filename)\n",
    "    \n",
    "        # Extract features for each augmentation\n",
    "        for aug_audio in [audio_noise, audio_pitch, audio_shift]:\n",
    "            zcr = extract_zcr_seq(aug_audio)\n",
    "            rms = extract_rms_seq(aug_audio)\n",
    "            mel = extract_mel_spectrogram(aug_audio, sr)\n",
    "    \n",
    "            time_feats = np.stack([zcr, rms], axis=0) # Stack time features -> (2, 157)\n",
    "            mel = mel[np.newaxis, :, :]  # Add channel dim -> (1, 128, 157)\n",
    "    \n",
    "            # Append to lists\n",
    "            aug_X_time.append(time_feats)\n",
    "            aug_X_mel.append(mel)\n",
    "            aug_y.append(emotion)\n",
    "            aug_y_gender.append(gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T06:58:10.165964Z",
     "iopub.status.busy": "2025-05-15T06:58:10.165743Z",
     "iopub.status.idle": "2025-05-15T06:58:10.177045Z",
     "shell.execute_reply": "2025-05-15T06:58:10.176458Z",
     "shell.execute_reply.started": "2025-05-15T06:58:10.165942Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(len(X_time_train)) # get number of samples in training before augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T06:58:10.177838Z",
     "iopub.status.busy": "2025-05-15T06:58:10.177681Z",
     "iopub.status.idle": "2025-05-15T06:58:10.190066Z",
     "shell.execute_reply": "2025-05-15T06:58:10.189398Z",
     "shell.execute_reply.started": "2025-05-15T06:58:10.177825Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if is_augmented:\n",
    "    X_time_train = np.concatenate([X_time_train, aug_X_time], axis=0)\n",
    "    X_mel_train = np.concatenate([X_mel_train, aug_X_mel], axis=0)\n",
    "    y_train = np.concatenate([y_train, aug_y], axis=0)\n",
    "    y_train_g = np.concatenate([y_train_g, aug_y_gender], axis=0)\n",
    "    \n",
    "    print(X_time_train.shape)\n",
    "    print(X_mel_train.shape)\n",
    "    print(y_train.shape)\n",
    "    print(y_train_g.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T06:58:10.190901Z",
     "iopub.status.busy": "2025-05-15T06:58:10.190694Z",
     "iopub.status.idle": "2025-05-15T06:58:10.202007Z",
     "shell.execute_reply": "2025-05-15T06:58:10.201322Z",
     "shell.execute_reply.started": "2025-05-15T06:58:10.190880Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if is_augmented:\n",
    "    # Shuffle the training set\n",
    "    num_samples = X_time_train.shape[0]\n",
    "    \n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    # Generate a shuffled index\n",
    "    shuffled_indices = np.random.permutation(num_samples)\n",
    "    \n",
    "    # Shuffle all arrays using the same indices\n",
    "    X_time_train = X_time_train[shuffled_indices]\n",
    "    X_mel_train = X_mel_train[shuffled_indices]\n",
    "    y_train = y_train[shuffled_indices]\n",
    "    y_train_g = y_train_g[shuffled_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T06:58:10.202955Z",
     "iopub.status.busy": "2025-05-15T06:58:10.202774Z",
     "iopub.status.idle": "2025-05-15T06:58:10.212311Z",
     "shell.execute_reply": "2025-05-15T06:58:10.211629Z",
     "shell.execute_reply.started": "2025-05-15T06:58:10.202941Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "normalize = False\n",
    "if normalize:\n",
    "    # Initialize scalers for ZCR and RMS\n",
    "    scaler_zcr = StandardScaler()\n",
    "    scaler_rms = StandardScaler()\n",
    "    \n",
    "    # Fit on training data (X_time_train) and transform all datasets\n",
    "    X_time_train[:, 0, :] = scaler_zcr.fit_transform(X_time_train[:, 0, :])  # Normalize ZCR\n",
    "    X_time_train[:, 1, :] = scaler_rms.fit_transform(X_time_train[:, 1, :])  # Normalize RMS\n",
    "    \n",
    "    # Apply the same transformation to validation and test sets\n",
    "    X_time_val[:, 0, :] = scaler_zcr.transform(X_time_val[:, 0, :])\n",
    "    X_time_val[:, 1, :] = scaler_rms.transform(X_time_val[:, 1, :])\n",
    "    \n",
    "    X_time_test[:, 0, :] = scaler_zcr.transform(X_time_test[:, 0, :])\n",
    "    X_time_test[:, 1, :] = scaler_rms.transform(X_time_test[:, 1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T06:58:10.216795Z",
     "iopub.status.busy": "2025-05-15T06:58:10.216562Z",
     "iopub.status.idle": "2025-05-15T06:58:10.239855Z",
     "shell.execute_reply": "2025-05-15T06:58:10.239063Z",
     "shell.execute_reply.started": "2025-05-15T06:58:10.216780Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# One-hot encode\n",
    "ohe = OneHotEncoder(sparse_output=False)\n",
    "y_train_oh = ohe.fit_transform(y_train.reshape(-1, 1))\n",
    "y_val_oh = ohe.transform(y_val.reshape(-1, 1))\n",
    "y_test_oh = ohe.transform(y_test.reshape(-1, 1))\n",
    "\n",
    "ohe_g = OneHotEncoder(sparse_output=False)\n",
    "y_train_oh_g = ohe_g.fit_transform(y_train_g.reshape(-1, 1))\n",
    "y_val_oh_g = ohe_g.transform(y_val_g.reshape(-1, 1))\n",
    "y_test_oh_g = ohe_g.transform(y_test_g.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T06:58:10.241083Z",
     "iopub.status.busy": "2025-05-15T06:58:10.240768Z",
     "iopub.status.idle": "2025-05-15T06:58:10.251682Z",
     "shell.execute_reply": "2025-05-15T06:58:10.251141Z",
     "shell.execute_reply.started": "2025-05-15T06:58:10.241046Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CremaDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# Convert data to the correct dtype\n",
    "X_time_train = X_time_train.astype(np.float32)\n",
    "X_time_val = X_time_val.astype(np.float32)\n",
    "X_time_test = X_time_test.astype(np.float32)\n",
    "\n",
    "y_train_oh = y_train_oh.astype(np.float32)\n",
    "y_val_oh = y_val_oh.astype(np.float32)\n",
    "y_test_oh = y_test_oh.astype(np.float32)\n",
    "y_train_oh_g = y_train_oh_g.astype(np.float32)\n",
    "y_val_oh_g = y_val_oh_g.astype(np.float32)\n",
    "y_test_oh_g = y_test_oh_g.astype(np.float32)\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# Create datasets for both y and y_gender\n",
    "time_train_loader = DataLoader(CremaDataset(X_time_train, y_train_oh), batch_size=batch_size, shuffle=True)\n",
    "time_val_loader = DataLoader(CremaDataset(X_time_val, y_val_oh), batch_size=batch_size)\n",
    "time_test_loader = DataLoader(CremaDataset(X_time_test, y_test_oh), batch_size=batch_size)\n",
    "\n",
    "time_train_loader_g = DataLoader(CremaDataset(X_time_train, y_train_oh_g), batch_size=batch_size, shuffle=True)\n",
    "time_val_loader_g = DataLoader(CremaDataset(X_time_val, y_val_oh_g), batch_size=batch_size)\n",
    "time_test_loader_g = DataLoader(CremaDataset(X_time_test, y_test_oh_g), batch_size=batch_size)\n",
    "\n",
    "# Repeat for mel data\n",
    "mel_train_loader = DataLoader(CremaDataset(X_mel_train, y_train_oh), batch_size=batch_size, shuffle=True)\n",
    "mel_val_loader = DataLoader(CremaDataset(X_mel_val, y_val_oh), batch_size=batch_size)\n",
    "mel_test_loader = DataLoader(CremaDataset(X_mel_test, y_test_oh), batch_size=batch_size)\n",
    "\n",
    "mel_train_loader_g = DataLoader(CremaDataset(X_mel_train, y_train_oh_g), batch_size=batch_size, shuffle=True)\n",
    "mel_val_loader_g = DataLoader(CremaDataset(X_mel_val, y_val_oh_g), batch_size=batch_size)\n",
    "mel_test_loader_g = DataLoader(CremaDataset(X_mel_test, y_test_oh_g), batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T06:58:10.252903Z",
     "iopub.status.busy": "2025-05-15T06:58:10.252671Z",
     "iopub.status.idle": "2025-05-15T06:58:10.264055Z",
     "shell.execute_reply": "2025-05-15T06:58:10.263450Z",
     "shell.execute_reply.started": "2025-05-15T06:58:10.252888Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class TimeNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(TimeNet, self).__init__()\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(in_channels=2, out_channels=256, kernel_size=3, stride=2, padding=1)  # (B, 256, 78)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2)  # (B, 256, 39)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(in_channels=256, out_channels=128, kernel_size=3, padding=1)  # (B, 128, 39)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=2)  # (B, 128, 19)\n",
    "\n",
    "        self.conv3 = nn.Conv1d(in_channels=128, out_channels=128, kernel_size=3, padding=1)  # (B, 128, 19)\n",
    "        self.pool3 = nn.MaxPool1d(kernel_size=2)  # (B, 128, 9)\n",
    "\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "\n",
    "        self.conv4 = nn.Conv1d(in_channels=128, out_channels=64, kernel_size=3, padding=1)  # (B, 64, 9)\n",
    "        self.pool4 = nn.AvgPool1d(kernel_size=2)  # (B, 64, 4)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(64 * 4, 32)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(32, num_classes)\n",
    "\n",
    "    def forward(self, x):  # x: (B, 2, 157)\n",
    "        x = self.relu(self.conv1(x))   # (B, 256, 78)\n",
    "        x = self.pool1(x)              # (B, 256, 39)\n",
    "\n",
    "        x = self.relu(self.conv2(x))   # (B, 128, 39)\n",
    "        x = self.pool2(x)              # (B, 128, 19)\n",
    "\n",
    "        x = self.relu(self.conv3(x))   # (B, 128, 19)\n",
    "        x = self.pool3(x)              # (B, 128, 9)\n",
    "\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = self.relu(self.conv4(x))   # (B, 64, 9)\n",
    "        x = self.pool4(x)              # (B, 64, 4)\n",
    "\n",
    "        x = self.flatten(x)            # (B, 256)\n",
    "        x = self.relu(self.fc1(x))     # (B, 32)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)                # (B, num_classes)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T06:58:10.264885Z",
     "iopub.status.busy": "2025-05-15T06:58:10.264730Z",
     "iopub.status.idle": "2025-05-15T06:58:10.277782Z",
     "shell.execute_reply": "2025-05-15T06:58:10.277185Z",
     "shell.execute_reply.started": "2025-05-15T06:58:10.264873Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def confusion_matrix_to_labels(cm):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for true_label in range(cm.shape[0]):\n",
    "        for pred_label in range(cm.shape[1]):\n",
    "            count = cm[true_label, pred_label]\n",
    "            y_true.extend([true_label] * count)\n",
    "            y_pred.extend([pred_label] * count)\n",
    "    return np.array(y_true), np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T06:58:10.278756Z",
     "iopub.status.busy": "2025-05-15T06:58:10.278492Z",
     "iopub.status.idle": "2025-05-15T06:58:10.291248Z",
     "shell.execute_reply": "2025-05-15T06:58:10.290529Z",
     "shell.execute_reply.started": "2025-05-15T06:58:10.278735Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate_and_pool_confusion_matrix(cm, class_names):\n",
    "    # 2x2 sum pooling\n",
    "    if cm.shape[0] % 2 != 0 or cm.shape[1] % 2 != 0:\n",
    "        raise ValueError(\"Confusion matrix dimensions must be even for 2x2 pooling.\")\n",
    "    \n",
    "    pooled_cm = []\n",
    "    \n",
    "    # Perform 2x2 sum pooling\n",
    "    for i in range(0, cm.shape[0], 2):\n",
    "        row = []\n",
    "        for j in range(0, cm.shape[1], 2):\n",
    "            block_sum = np.sum(cm[i:i+2, j:j+2])  # Sum the 2x2 block\n",
    "            row.append(block_sum)\n",
    "        pooled_cm.append(row)\n",
    "    \n",
    "    pooled_cm = np.array(pooled_cm)\n",
    "    y_true, y_pred = confusion_matrix_to_labels(pooled_cm)\n",
    "    # Calculate accuracy and F1 score\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "    print(\"Accuracy:\", acc)\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "\n",
    "    # Display the pooled confusion matrix\n",
    "    sns.heatmap(pooled_cm, annot=True, fmt='d', xticklabels=class_names[::], yticklabels=class_names[::], cmap='Blues')\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.title(\"Pooled Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "    return acc, f1, pooled_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T06:58:10.303754Z",
     "iopub.status.busy": "2025-05-15T06:58:10.303498Z",
     "iopub.status.idle": "2025-05-15T06:58:10.317282Z",
     "shell.execute_reply": "2025-05-15T06:58:10.316551Z",
     "shell.execute_reply.started": "2025-05-15T06:58:10.303731Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, y_val, class_names,\n",
    "                epochs=100, lr=0.001, patience=10, pool = False,isTuning = False):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    best_model_state = None\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_correct= 0\n",
    "    train_total=0\n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            labels = torch.argmax(y_batch, dim=1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            train_total += labels.size(0)\n",
    "            \n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                X_batch = X_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                outputs = model(X_batch)\n",
    "                loss = criterion(outputs, torch.argmax(y_batch, dim=1))\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "        train_losses.append(avg_train_loss)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Avg. Train Loss: {avg_train_loss:.4f} - Avg. Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "        # Early Stopping Check\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "            best_model_state = model.state_dict()  # Save best model\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping triggered after {epoch+1} epochs.\")\n",
    "                break\n",
    "    # Plot losses over epochs\n",
    "    if(not isTuning):\n",
    "        plt.plot(train_losses, label='Avg. Train Loss')\n",
    "        plt.plot(val_losses, label='Avg. Val Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Training vs Validation Loss')\n",
    "        plt.xticks(range(0, len(train_losses), 10))\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    # Load the best model before returning\n",
    "    if best_model_state:\n",
    "        model.load_state_dict(best_model_state)\n",
    "    if(not isTuning):\n",
    "        print(\"Training complete.\")\n",
    "        train_accuracy = train_correct / train_total\n",
    "        print(f\"Total Train Accuracy: {train_accuracy:.4f}\")\n",
    "        print(\"Evaluating on validation set...\")\n",
    "    acc, f1, cm, report = evaluate_model(model, val_loader, y_val, class_names, pool,isTuning)\n",
    "    return model, acc, f1, cm, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T06:58:10.292153Z",
     "iopub.status.busy": "2025-05-15T06:58:10.291942Z",
     "iopub.status.idle": "2025-05-15T06:58:10.302711Z",
     "shell.execute_reply": "2025-05-15T06:58:10.302053Z",
     "shell.execute_reply.started": "2025-05-15T06:58:10.292129Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, data_loader, y_true_onehot, class_names, pool=False,isTuning = False ):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, _ in data_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            outputs = model(X_batch)\n",
    "            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "\n",
    "    y_true = np.argmax(y_true_onehot, axis=1)\n",
    "    acc = accuracy_score(y_true, all_preds)\n",
    "    f1 = f1_score(y_true, all_preds, average='weighted')\n",
    "    cm = confusion_matrix(y_true, all_preds)\n",
    "    report = classification_report(y_true, all_preds, target_names=class_names, output_dict=True)\n",
    "    if pool:\n",
    "        reduced_class_names = [name.split('_')[0] for i, name in enumerate(class_names) if i % 2 == 0]\n",
    "        acc, f1, pooled_cm = evaluate_and_pool_confusion_matrix(cm, reduced_class_names)\n",
    "        return acc, f1, pooled_cm, report\n",
    "    if(not isTuning):\n",
    "        print(\"Accuracy:\", acc)\n",
    "        print(\"F1 Score:\", f1)\n",
    "        print(\"Classification Report:\")\n",
    "        print(classification_report(y_true, all_preds, target_names=class_names))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_names, yticklabels=class_names, cmap='Blues')\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"True\")\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        plt.show()\n",
    "\n",
    "    return acc, f1, cm, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T06:58:10.318186Z",
     "iopub.status.busy": "2025-05-15T06:58:10.317993Z",
     "iopub.status.idle": "2025-05-15T06:58:10.330484Z",
     "shell.execute_reply": "2025-05-15T06:58:10.329799Z",
     "shell.execute_reply.started": "2025-05-15T06:58:10.318171Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def set_seed(seed=RANDOM_SEED):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T06:58:10.331502Z",
     "iopub.status.busy": "2025-05-15T06:58:10.331270Z",
     "iopub.status.idle": "2025-05-15T06:58:39.274085Z",
     "shell.execute_reply": "2025-05-15T06:58:39.273513Z",
     "shell.execute_reply.started": "2025-05-15T06:58:10.331481Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "set_seed(RANDOM_SEED)\n",
    "time_model = TimeNet(num_classes=y_train_oh.shape[1])\n",
    "time_model, time_acc, time_f1, time_cm, time_report = train_model(time_model, time_train_loader, time_val_loader, y_val_oh, class_names=ohe.categories_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T06:58:39.275240Z",
     "iopub.status.busy": "2025-05-15T06:58:39.274786Z",
     "iopub.status.idle": "2025-05-15T06:58:39.570128Z",
     "shell.execute_reply": "2025-05-15T06:58:39.569349Z",
     "shell.execute_reply.started": "2025-05-15T06:58:39.275220Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Evaluating the Time-domain model on Test Set\")\n",
    "test_time_acc, test_time_f1, test_time_cm, test_time_report = evaluate_model(time_model, time_test_loader, y_test_oh, class_names=ohe.categories_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T06:58:39.571128Z",
     "iopub.status.busy": "2025-05-15T06:58:39.570904Z",
     "iopub.status.idle": "2025-05-15T06:59:46.440541Z",
     "shell.execute_reply": "2025-05-15T06:59:46.439768Z",
     "shell.execute_reply.started": "2025-05-15T06:58:39.571110Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "set_seed(RANDOM_SEED)\n",
    "time_model_g = TimeNet(num_classes=y_train_oh_g.shape[1])\n",
    "time_model_g, time_acc_g, time_f1_g, time_cm_g, time_report_g = train_model(time_model_g, time_train_loader_g, time_val_loader_g, y_val_oh_g, class_names=ohe_g.categories_[0], patience = 30, epochs = 200, pool = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T06:59:46.441864Z",
     "iopub.status.busy": "2025-05-15T06:59:46.441361Z",
     "iopub.status.idle": "2025-05-15T06:59:46.730502Z",
     "shell.execute_reply": "2025-05-15T06:59:46.729781Z",
     "shell.execute_reply.started": "2025-05-15T06:59:46.441839Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Evaluating the Time-domain (Gender) model on Test Set\")\n",
    "test_time_acc_g, test_time_f1_g, test_time_cm_g, test_time_report_g = evaluate_model(time_model_g, time_test_loader_g, y_test_oh_g, class_names=ohe_g.categories_[0], pool = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T06:59:46.731484Z",
     "iopub.status.busy": "2025-05-15T06:59:46.731292Z",
     "iopub.status.idle": "2025-05-15T06:59:46.742003Z",
     "shell.execute_reply": "2025-05-15T06:59:46.741364Z",
     "shell.execute_reply.started": "2025-05-15T06:59:46.731469Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate_fused_models(\n",
    "    model, report_model, model_g, report_model_g, data_loader, y_true_onehot, class_names\n",
    "):\n",
    "    model.eval()\n",
    "    model_g.eval()\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    # Extract F1 scores for coarse model (6 classes)\n",
    "    f1_model = np.array([report_model[cls]['f1-score'] for cls in class_names])\n",
    "\n",
    "    # Pool F1 scores from fine-grained model_g (12 classes)\n",
    "    f1_model_g = []\n",
    "    for cls in class_names:\n",
    "        f1_female = report_model_g.get(f\"{cls}_female\", {'f1-score': 0.0}).get('f1-score', 0.0)\n",
    "        f1_male = report_model_g.get(f\"{cls}_male\", {'f1-score': 0.0}).get('f1-score', 0.0)\n",
    "        f1_model_g.append(f1_female + f1_male)\n",
    "    f1_model_g = np.array(f1_model_g)\n",
    "\n",
    "    # Normalize the F1 scores to use as weights (total weight = 1)\n",
    "    total_f1 = np.sum(f1_model + f1_model_g)\n",
    "    f1_model_normalized = (f1_model / total_f1)  # Normalize coarse model F1 scores\n",
    "    f1_model_g_normalized = (f1_model_g / total_f1)  # Normalize fine model F1 scores\n",
    "\n",
    "    # Combine the model weights\n",
    "    class_weights = f1_model_normalized + f1_model_g_normalized\n",
    "\n",
    "    y_true = np.argmax(y_true_onehot, axis=1)\n",
    "    all_preds_fused = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, _ in data_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "\n",
    "            out_model = torch.softmax(model(X_batch), dim=1).cpu().numpy()         # (B, 6)\n",
    "            out_model_g = torch.softmax(model_g(X_batch), dim=1).cpu().numpy()     # (B, 12)\n",
    "\n",
    "            # Pool the gender-specific outputs\n",
    "            out_model_g_pooled = out_model_g[:, ::2] + out_model_g[:, 1::2]  # (B, 6)\n",
    "\n",
    "            # Fusion with exponential weighting: Prioritize the more confident model\n",
    "            alpha = 2.0  # Exponential scaling factor\n",
    "            fused_probs = np.exp(alpha * f1_model_normalized) * out_model + np.exp(alpha * f1_model_g_normalized) * out_model_g_pooled\n",
    "            fused_probs /= np.sum(np.exp(alpha * np.array([f1_model_normalized, f1_model_g_normalized])), axis=0)\n",
    "\n",
    "            preds_fused = np.argmax(fused_probs, axis=1)\n",
    "            all_preds_fused.extend(preds_fused)\n",
    "\n",
    "    acc = accuracy_score(y_true, all_preds_fused)\n",
    "    f1 = f1_score(y_true, all_preds_fused, average='weighted')\n",
    "    report = classification_report(y_true, all_preds_fused, target_names=class_names, output_dict=True)\n",
    "    print(f\"Fused Accuracy: {acc}\")\n",
    "    print(f\"Fused F1 Score: {f1}\")\n",
    "    print(\"Fused Classification Report:\")\n",
    "    print(classification_report(y_true, all_preds_fused, target_names=class_names))\n",
    "\n",
    "    cm = confusion_matrix(y_true, all_preds_fused)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_names, yticklabels=class_names, cmap='Blues')\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.title(\"Fused Confusion Matrix (Exponential Weighted Fusion)\")\n",
    "    plt.show()\n",
    "\n",
    "    return acc, f1, cm, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T06:59:46.743581Z",
     "iopub.status.busy": "2025-05-15T06:59:46.742832Z",
     "iopub.status.idle": "2025-05-15T06:59:46.756628Z",
     "shell.execute_reply": "2025-05-15T06:59:46.755949Z",
     "shell.execute_reply.started": "2025-05-15T06:59:46.743563Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrices(cm_list, titles, class_names):\n",
    "    if len(cm_list) != len(titles):\n",
    "        raise ValueError(\"The number of confusion matrices must match the number of titles.\")\n",
    "\n",
    "    n = len(cm_list)\n",
    "    cols = min(n, 3)\n",
    "    rows = math.ceil(n / cols)\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(6 * cols, 5 * rows))\n",
    "    axes = axes.flatten() if n > 1 else [axes]\n",
    "\n",
    "    for i, (cm, title) in enumerate(zip(cm_list, titles)):\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                    xticklabels=class_names, yticklabels=class_names, ax=axes[i])\n",
    "        axes[i].set_xlabel(\"Predicted\")\n",
    "        axes[i].set_ylabel(\"True\")\n",
    "        axes[i].set_title(title)\n",
    "\n",
    "    # Hide unused subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T06:59:46.757539Z",
     "iopub.status.busy": "2025-05-15T06:59:46.757309Z",
     "iopub.status.idle": "2025-05-15T06:59:47.876650Z",
     "shell.execute_reply": "2025-05-15T06:59:47.875899Z",
     "shell.execute_reply.started": "2025-05-15T06:59:46.757518Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Evaluating the Time-domain (Fused) models on Validation Set\")\n",
    "time_acc_f, time_f1_f, time_cm_f, time_report_f = evaluate_fused_models(time_model, time_report, time_model_g, time_report_g, time_val_loader, y_val_oh, ohe.categories_[0])\n",
    "plot_confusion_matrices([time_cm, time_cm_g, time_cm_f], [f\"Original ({100*time_acc:.2f}%)\", f\"Gender ({100*time_acc_g:.2f}%)\", f\"Fused ({100*time_acc_f:.2f}%)\"], ohe.categories_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T06:59:47.877767Z",
     "iopub.status.busy": "2025-05-15T06:59:47.877488Z",
     "iopub.status.idle": "2025-05-15T06:59:49.077749Z",
     "shell.execute_reply": "2025-05-15T06:59:49.076894Z",
     "shell.execute_reply.started": "2025-05-15T06:59:47.877749Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Evaluating the Time-domain (Fused) models on Test Set\")\n",
    "test_time_acc_f, test_time_f1_f, test_time_cm_f, test_time_report_g = evaluate_fused_models(time_model, time_report, time_model_g, time_report_g, time_test_loader, y_test_oh, ohe.categories_[0])\n",
    "plot_confusion_matrices([test_time_cm, test_time_cm_g, test_time_cm_f], [f\"Original ({100*test_time_acc:.2f}%)\", f\"Gender ({100*test_time_acc_g:.2f}%)\", f\"Fused ({100*test_time_acc_f:.2f}%)\"], ohe.categories_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T06:59:49.078855Z",
     "iopub.status.busy": "2025-05-15T06:59:49.078579Z",
     "iopub.status.idle": "2025-05-15T06:59:49.083107Z",
     "shell.execute_reply": "2025-05-15T06:59:49.082322Z",
     "shell.execute_reply.started": "2025-05-15T06:59:49.078829Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# class FreqNet(nn.Module):\n",
    "#     def __init__(self, num_classes):\n",
    "#         super(FreqNet, self).__init__()\n",
    "\n",
    "#         def conv_block(in_channels, out_channels, kernel_size):\n",
    "#             return nn.Sequential(\n",
    "#                 nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=kernel_size // 2),\n",
    "#                 nn.BatchNorm2d(out_channels),\n",
    "#                 nn.ReLU(),\n",
    "#                 nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "#                 nn.BatchNorm2d(out_channels),\n",
    "#                 nn.ReLU(),\n",
    "#                 nn.MaxPool2d(2),\n",
    "#                 nn.Dropout(0.2)\n",
    "#             )\n",
    "\n",
    "#         self.branch1 = conv_block(1, 32, kernel_size=3)\n",
    "#         self.branch2 = conv_block(1, 32, kernel_size=5)\n",
    "#         self.branch3 = conv_block(1, 32, kernel_size=7)\n",
    "\n",
    "#         self.shared_block = nn.Sequential(\n",
    "#             nn.Conv2d(96, 128, kernel_size=3, padding=1),\n",
    "#             nn.BatchNorm2d(128),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "#             nn.BatchNorm2d(128),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(2),\n",
    "#             nn.Dropout(0.3)\n",
    "#         )\n",
    "\n",
    "#         self.global_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "#         self.classifier = nn.Sequential(\n",
    "#             nn.Linear(128, 128),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(0.4),\n",
    "#             nn.Linear(128, 64),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(0.3),\n",
    "#             nn.Linear(64, num_classes)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x1 = self.branch1(x)\n",
    "#         x2 = self.branch2(x)\n",
    "#         x3 = self.branch3(x)\n",
    "\n",
    "#         x_concat = torch.cat([x1, x2, x3], dim=1)\n",
    "#         x = self.shared_block(x_concat)\n",
    "#         x = self.global_pool(x)\n",
    "#         x = x.view(x.size(0), -1)\n",
    "#         return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T07:01:08.948703Z",
     "iopub.status.busy": "2025-05-15T07:01:08.947949Z",
     "iopub.status.idle": "2025-05-15T07:01:08.955251Z",
     "shell.execute_reply": "2025-05-15T07:01:08.954452Z",
     "shell.execute_reply.started": "2025-05-15T07:01:08.948673Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class FreqNet(nn.Module):\n",
    "    def __init__(self, num_classes=6):  \n",
    "        super(FreqNet, self).__init__()  \n",
    "        self.conv1 = nn.Conv2d(1, 128, kernel_size=7, padding=3)\n",
    "        self.pool1 = nn.MaxPool2d(2, stride=2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(128, 256, kernel_size=7, padding=3)\n",
    "        self.pool2 = nn.MaxPool2d(2, stride=2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(256, 256, kernel_size=7, padding=3)\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "        self.fc1 = nn.Linear(256, 64)\n",
    "        self.fc2 = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))   # (B, 128, H, W)\n",
    "        x = self.pool1(x)           # (B, 128, H/2, W/2)\n",
    "        x = F.relu(self.conv2(x))   # (B, 256, H/2, W/2)\n",
    "        x = self.pool2(x)           # (B, 256, H/4, W/4)\n",
    "        x = F.relu(self.conv3(x))   # (B, 256, H/4, W/4)\n",
    "        x = self.global_avg_pool(x) # (B, 256, 1, 1)\n",
    "        x = x.view(x.size(0), -1)   # (B, 256)\n",
    "        x = F.relu(self.fc1(x))     # (B, 64)\n",
    "        x = self.fc2(x)             # (B, num_classes)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "set_seed(RANDOM_SEED)\n",
    "mel_model = FreqNet(num_classes=y_train_oh.shape[1])\n",
    "\n",
    "mel_model, mel_acc, mel_f1, mel_cm, mel_report = train_model(\n",
    "    mel_model,\n",
    "    mel_train_loader,\n",
    "    mel_val_loader,\n",
    "    y_val_oh,\n",
    "    class_names=ohe.categories_[0],\n",
    "    lr=0.00001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "set_seed(RANDOM_SEED)\n",
    "mel_model_g = FreqNet(num_classes=y_train_oh_g.shape[1])\n",
    "\n",
    "mel_model_g, mel_acc_g, mel_f1_g, mel_cm_g, mel_report_g = train_model(\n",
    "    mel_model_g,\n",
    "    mel_train_loader_g,\n",
    "    mel_val_loader_g,\n",
    "    y_val_oh_g,\n",
    "    class_names=ohe_g.categories_[0],\n",
    "    pool = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T07:51:01.850514Z",
     "iopub.status.busy": "2025-05-15T07:51:01.850225Z",
     "iopub.status.idle": "2025-05-15T07:51:05.181580Z",
     "shell.execute_reply": "2025-05-15T07:51:05.180884Z",
     "shell.execute_reply.started": "2025-05-15T07:51:01.850492Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Evaluating the Frequency-domain model on Test Set\")\n",
    "test_mel_acc, test_mel_f1, test_mel_cm, test_mel_report = evaluate_model(\n",
    "    mel_model,\n",
    "    mel_test_loader,\n",
    "    y_test_oh,\n",
    "    class_names=ohe.categories_[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-15T06:59:49.204046Z",
     "iopub.status.idle": "2025-05-15T06:59:49.204352Z",
     "shell.execute_reply": "2025-05-15T06:59:49.204185Z",
     "shell.execute_reply.started": "2025-05-15T06:59:49.204169Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Evaluating the Frequency-domain (Gender) model on Test Set\")\n",
    "test_mel_acc_g, test_mel_f1_g, test_mel_cm_g, test_mel_report_g = evaluate_model(\n",
    "    mel_model_g,\n",
    "    mel_test_loader_g,\n",
    "    y_test_oh_g,\n",
    "    class_names=ohe_g.categories_[0],\n",
    "    pool = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-15T06:59:49.206098Z",
     "iopub.status.idle": "2025-05-15T06:59:49.206357Z",
     "shell.execute_reply": "2025-05-15T06:59:49.206249Z",
     "shell.execute_reply.started": "2025-05-15T06:59:49.206238Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Evaluating the Fequency-domain (Fused) models on Validation Set\")\n",
    "mel_acc_f, mel_f1_f, mel_cm_f, mel_report_f = evaluate_fused_models(mel_model, mel_report, mel_model_g, mel_report_g, mel_val_loader, y_val_oh, ohe.categories_[0])\n",
    "plot_confusion_matrices([mel_cm, mel_cm_g, mel_cm_f], [f\"Original ({100*mel_acc:.2f}%)\", f\"Gender ({100*mel_acc_g:.2f}%)\", f\"Fused ({100*mel_acc_f:.2f}%)\"], ohe.categories_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-15T06:59:49.207221Z",
     "iopub.status.idle": "2025-05-15T06:59:49.207424Z",
     "shell.execute_reply": "2025-05-15T06:59:49.207338Z",
     "shell.execute_reply.started": "2025-05-15T06:59:49.207329Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Evaluating the Frequency-domain (Fused) models on Test Set\")\n",
    "test_mel_acc_f, test_mel_f1_f, test_mel_cm_f, test_mel_report_f = evaluate_fused_models(mel_model, mel_report, mel_model_g, mel_report_g, mel_test_loader, y_test_oh, ohe.categories_[0])\n",
    "plot_confusion_matrices([test_mel_cm, test_mel_cm_g, test_mel_cm_f], [f\"Original ({100*test_mel_acc:.2f}%)\", f\"Gender ({100*test_mel_acc_g:.2f}%)\", f\"Fused ({100*test_mel_acc_f:.2f}%)\"], ohe.categories_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALL Models with best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T11:29:49.859725Z",
     "iopub.status.busy": "2025-05-15T11:29:49.858992Z",
     "iopub.status.idle": "2025-05-15T11:29:49.988540Z",
     "shell.execute_reply": "2025-05-15T11:29:49.987765Z",
     "shell.execute_reply.started": "2025-05-15T11:29:49.859698Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Paths to model files\n",
    "model_paths = {\n",
    "    \"mel_model\": \"/kaggle/input/mel_model/pytorch/default/1/mel_model.pth\",\n",
    "    \"mel_model_g\": \"/kaggle/input/mel_model_g/pytorch/default/1/mel_model_g.pth\",\n",
    "    \"time_model\": \"/kaggle/input/time_model/pytorch/default/1/time_model.pth\",\n",
    "    \"time_model_g\": \"/kaggle/input/time_model_g/pytorch/default/1/time_model_g.pth\"\n",
    "}\n",
    "\n",
    "# Class mapping for each model\n",
    "model_classes = {\n",
    "    \"mel_model\": FreqNet,\n",
    "    \"mel_model_g\": FreqNet,\n",
    "    \"time_model\": TimeNet,\n",
    "    \"time_model_g\": TimeNet\n",
    "}\n",
    "\n",
    "# Correct number of output classes per model\n",
    "model_num_classes = {\n",
    "    \"mel_model\": 6,\n",
    "    \"mel_model_g\": 12,\n",
    "    \"time_model\": 6,\n",
    "    \"time_model_g\": 12\n",
    "}\n",
    "\n",
    "# Dictionary to hold loaded models\n",
    "loaded_models = {}\n",
    "\n",
    "# Load each model properly\n",
    "for name, path in model_paths.items():\n",
    "    model_class = model_classes[name]\n",
    "    num_classes = model_num_classes[name]\n",
    "    \n",
    "    # Instantiate and load the model\n",
    "    model = model_class(num_classes=num_classes)\n",
    "    model.load_state_dict(torch.load(path, map_location=device, weights_only=True))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    loaded_models[name] = model\n",
    "    print(f\"Loaded and ready: {name}\")\n",
    "\n",
    "mel_model = loaded_models[\"mel_model\"]\n",
    "mel_model_g = loaded_models[\"mel_model_g\"]\n",
    "time_model_g = loaded_models[\"time_model_g\"]\n",
    "time_model = loaded_models[\"time_model\"]\n",
    "# mel_model.eval()\n",
    "# mel_model_g.eval()\n",
    "# time_model_g.eval()\n",
    "# time_model.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T11:33:26.080006Z",
     "iopub.status.busy": "2025-05-15T11:33:26.079309Z",
     "iopub.status.idle": "2025-05-15T11:33:40.916546Z",
     "shell.execute_reply": "2025-05-15T11:33:40.915756Z",
     "shell.execute_reply.started": "2025-05-15T11:33:26.079975Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "mel_acc, mel_f1, mel_cm, mel_report = evaluate_model(\n",
    "    mel_model,\n",
    "    mel_val_loader,\n",
    "    y_val_oh,\n",
    "    class_names=ohe.categories_[0]\n",
    ")\n",
    "\n",
    "print(\"Evaluating the Frequency-domain model on Test Set\")\n",
    "test_mel_acc, test_mel_f1, test_mel_cm, test_mel_report = evaluate_model(\n",
    "    mel_model,\n",
    "    mel_test_loader,\n",
    "    y_test_oh,\n",
    "    class_names=ohe.categories_[0]\n",
    ")\n",
    "mel_acc_g, mel_f1_g, mel_cm_g, mel_report_g = evaluate_model(\n",
    "    mel_model_g,\n",
    "    mel_val_loader_g,\n",
    "    y_val_oh_g,\n",
    "    class_names=ohe_g.categories_[0],\n",
    "    pool = True\n",
    ")\n",
    "\n",
    "print(\"Evaluating the Frequency-domain (Gender) model on Test Set\")\n",
    "test_mel_acc_g, test_mel_f1_g, test_mel_cm_g, test_mel_report_g = evaluate_model(\n",
    "    mel_model_g,\n",
    "    mel_test_loader_g,\n",
    "    y_test_oh_g,\n",
    "    class_names=ohe_g.categories_[0],\n",
    "    pool = True\n",
    ")\n",
    "print(\"Evaluating the Frequency-domain (Fused) models on Test Set\")\n",
    "test_mel_acc_f, test_mel_f1_f, test_mel_cm_f, test_mel_report_f = evaluate_fused_models(mel_model, mel_report, mel_model_g, mel_report_g, mel_test_loader, y_test_oh, ohe.categories_[0])\n",
    "plot_confusion_matrices([test_mel_cm, test_mel_cm_g, test_mel_cm_f], [f\"Original ({100*test_mel_acc:.2f}%)\", f\"Gender ({100*test_mel_acc_g:.2f}%)\", f\"Fused ({100*test_mel_acc_f:.2f}%)\"], ohe.categories_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T11:32:49.114895Z",
     "iopub.status.busy": "2025-05-15T11:32:49.114329Z",
     "iopub.status.idle": "2025-05-15T11:32:52.539817Z",
     "shell.execute_reply": "2025-05-15T11:32:52.539066Z",
     "shell.execute_reply.started": "2025-05-15T11:32:49.114871Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(ohe.categories_[0])\n",
    "time_acc, time_f1, time_cm, time_report = evaluate_model(time_model, time_val_loader, y_val_oh, class_names=ohe.categories_[0])\n",
    "\n",
    "print(\"Evaluating the Time-domain model on Test Set\")\n",
    "test_time_acc, test_time_f1, test_time_cm, test_time_report = evaluate_model(time_model, time_test_loader, y_test_oh, class_names=ohe.categories_[0])\n",
    "\n",
    "time_acc_g, time_f1_g, time_cm_g, time_report_g = evaluate_model(time_model_g, time_val_loader_g, y_val_oh_g, class_names=ohe_g.categories_[0], pool = True)\n",
    "\n",
    "print(\"Evaluating the Time-domain (Gender) model on Test Set\")\n",
    "test_time_acc_g, test_time_f1_g, test_time_cm_g, test_time_report_g = evaluate_model(time_model_g, time_test_loader_g, y_test_oh_g, class_names=ohe_g.categories_[0], pool = True)\n",
    "\n",
    "print(\"Evaluating the Time-domain (Fused) models on Validation Set\")\n",
    "time_acc_f, time_f1_f, time_cm_f, time_report_f = evaluate_fused_models(time_model, time_report, time_model_g, time_report_g, time_val_loader, y_val_oh, ohe.categories_[0])\n",
    "plot_confusion_matrices([time_cm, time_cm_g, time_cm_f], [f\"Original ({100*time_acc:.2f}%)\", f\"Gender ({100*time_acc_g:.2f}%)\", f\"Fused ({100*time_acc_f:.2f}%)\"], ohe.categories_[0])\n",
    "print(\"Evaluating the Time-domain (Fused) models on Test Set\")\n",
    "\n",
    "print(\"Evaluating the Time-domain (Fused) models on Test Set\")\n",
    "test_time_acc_f, test_time_f1_f, test_time_cm_f, test_time_report_g = evaluate_fused_models(time_model, time_report, time_model_g, time_report_g, time_test_loader, y_test_oh, ohe.categories_[0])\n",
    "plot_confusion_matrices([test_time_cm, test_time_cm_g, test_time_cm_f], [f\"Original ({100*test_time_acc:.2f}%)\", f\"Gender ({100*test_time_acc_g:.2f}%)\", f\"Fused ({100*test_time_acc_f:.2f}%)\"], ohe.categories_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T11:33:40.917754Z",
     "iopub.status.busy": "2025-05-15T11:33:40.917533Z",
     "iopub.status.idle": "2025-05-15T11:33:43.139937Z",
     "shell.execute_reply": "2025-05-15T11:33:43.139015Z",
     "shell.execute_reply.started": "2025-05-15T11:33:40.917736Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrices([\n",
    "    test_time_cm, test_time_cm_g, test_time_cm_f, \n",
    "    test_mel_cm, test_mel_cm_g, test_mel_cm_f], [\n",
    "    f\"Original Time ({100*test_time_acc:.2f}%)\", f\"Gender Time ({100*test_time_acc_g:.2f}%)\", f\"Fused Time ({100*test_time_acc_f:.2f}%)\", \n",
    "    f\"Original Mel ({100*test_mel_acc:.2f}%)\", f\"Gender Mel ({100*test_mel_acc_g:.2f}%)\", f\"Fused Mel ({100*test_mel_acc_f:.2f}%)\",], \n",
    "    ohe.categories_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hyperparameter Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T07:55:17.500320Z",
     "iopub.status.busy": "2025-05-15T07:55:17.500039Z",
     "iopub.status.idle": "2025-05-15T07:55:17.508916Z",
     "shell.execute_reply": "2025-05-15T07:55:17.508230Z",
     "shell.execute_reply.started": "2025-05-15T07:55:17.500297Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def tune_and_save_best_model(\n",
    "    model_class,\n",
    "    param_grid,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    y_val,\n",
    "    class_names,\n",
    "    num_classes,\n",
    "    model_name, \n",
    "    output_dir='/kaggle/working'\n",
    "):\n",
    "    best_f1 = -1\n",
    "    best_model = None\n",
    "    best_params = {}\n",
    "    best_acc = 0.0\n",
    "\n",
    "    all_combinations = list(itertools.product(*param_grid.values()))\n",
    "\n",
    "    for combo in all_combinations:\n",
    "        params = dict(zip(param_grid.keys(), combo))\n",
    "        print(f\"\\nTrying config: {params}...\")\n",
    "\n",
    "        model = model_class(num_classes=num_classes)\n",
    "\n",
    "        trained_model, acc, f1, cm, report = train_model(\n",
    "            model=model,\n",
    "            train_loader=train_loader,\n",
    "            val_loader=val_loader,\n",
    "            y_val=y_val,\n",
    "            class_names=class_names,\n",
    "            epochs=params.get('epochs', 100),\n",
    "            lr=params.get('lr', 0.001),\n",
    "            patience=params.get('patience', 10),\n",
    "            isTuning = False\n",
    "        )\n",
    "\n",
    "        print(f\"F1 Score = {f1:.4f}, Accuracy = {acc:.4f}\")\n",
    "\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_acc = acc\n",
    "            best_model = trained_model\n",
    "            best_params = params\n",
    "\n",
    "    if best_model:\n",
    "        # Save under /kaggle/working/models/model_name/\n",
    "        model_dir = os.path.join(output_dir, \"models\", model_name)\n",
    "        os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "        # base_filename = f\"{model_name}_f1_{best_f1:.4f}_acc_{best_acc:.4f}\"\n",
    "        # save_path = os.path.join(model_dir, base_filename + \".pth\")\n",
    "        # meta_path = os.path.join(model_dir, base_filename + \"_meta.json\")\n",
    "        save_path = os.path.join(model_dir, f\"{model_name}.pth\")\n",
    "        meta_path = os.path.join(model_dir, f\"{model_name}_meta.json\")\n",
    "        # Save model weights\n",
    "        torch.save(best_model.state_dict(), save_path)\n",
    "\n",
    "        # Save metadata\n",
    "        meta = {\n",
    "            \"best_params\": best_params,\n",
    "            \"best_f1\": best_f1,\n",
    "            \"best_acc\": best_acc,\n",
    "            \"model_path\": save_path\n",
    "        }\n",
    "        with open(meta_path, \"w\") as f:\n",
    "            json.dump(meta, f, indent=4)\n",
    "\n",
    "        print(f\"\\n Best model saved to: {save_path}\")\n",
    "        print(f\"Metadata saved to: {meta_path}\")\n",
    "    else:\n",
    "        save_path = None\n",
    "        print(\" No valid model was trained.\")\n",
    "    best_model.eval()\n",
    "    return best_params, best_f1, save_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T07:55:20.107574Z",
     "iopub.status.busy": "2025-05-15T07:55:20.107298Z",
     "iopub.status.idle": "2025-05-15T07:59:35.268021Z",
     "shell.execute_reply": "2025-05-15T07:59:35.267356Z",
     "shell.execute_reply.started": "2025-05-15T07:55:20.107553Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'lr': [0.005, 0.001, 0.0001],\n",
    "    'epochs': [50, 100],\n",
    "    'patience': [10, 15]\n",
    "}\n",
    "\n",
    "\n",
    "best_params, best_f1, saved_path = tune_and_save_best_model(\n",
    "    model_class=TimeNet,\n",
    "    param_grid=param_grid,\n",
    "    train_loader=time_train_loader,\n",
    "    val_loader=time_val_loader,\n",
    "    y_val=y_val_oh,\n",
    "    class_names=ohe.categories_[0],\n",
    "    num_classes=y_train_oh.shape[1],\n",
    "    model_name=\"time_Model\"\n",
    ")\n",
    "# best_params, best_f1, saved_path = tune_and_save_best_model(\n",
    "#     model_class=FreqNet,  \n",
    "#     param_grid=param_grid,\n",
    "#     train_loader=mel_train_loader,\n",
    "#     val_loader=mel_val_loader,\n",
    "#     y_val=y_val_oh,\n",
    "#     class_names=ohe.categories_[0],\n",
    "#     num_classes=y_train_oh.shape[1],  \n",
    "#     model_name=\"mal1_Model\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-05-15T08:01:00.432050Z",
     "iopub.status.busy": "2025-05-15T08:01:00.431443Z",
     "iopub.status.idle": "2025-05-15T09:50:58.267910Z",
     "shell.execute_reply": "2025-05-15T09:50:58.267253Z",
     "shell.execute_reply.started": "2025-05-15T08:01:00.432028Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'lr': [0.005, 0.001],\n",
    "    'epochs': [20, 30],\n",
    "    'patience': [5, 10]\n",
    "}\n",
    "\n",
    "best_params, best_f1, saved_path = tune_and_save_best_model(\n",
    "    model_class=FreqNet,  \n",
    "    param_grid=param_grid,\n",
    "    train_loader=mel_train_loader,\n",
    "    val_loader=mel_val_loader,\n",
    "    y_val=y_val_oh,\n",
    "    class_names=ohe.categories_[0],\n",
    "    num_classes=y_train_oh.shape[1],  \n",
    "    model_name=\"mal_Model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T09:52:32.908931Z",
     "iopub.status.busy": "2025-05-15T09:52:32.908213Z",
     "iopub.status.idle": "2025-05-15T09:52:32.915953Z",
     "shell.execute_reply": "2025-05-15T09:52:32.915123Z",
     "shell.execute_reply.started": "2025-05-15T09:52:32.908905Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_model_from_folder(model_class, model_name, num_classes, base_path='/kaggle/working/models'):\n",
    "    model_dir = os.path.join(base_path, model_name)\n",
    "    \n",
    "    if not os.path.exists(model_dir):\n",
    "        raise FileNotFoundError(f\"Directory '{model_dir}' does not exist.\")\n",
    "    \n",
    "    # Load model weights\n",
    "    pth_files = [f for f in os.listdir(model_dir) if f.endswith('.pth')]\n",
    "    if not pth_files:\n",
    "        raise FileNotFoundError(f\"No .pth file found in '{model_dir}'.\")\n",
    "    model_path = os.path.join(model_dir, pth_files[0])\n",
    "    \n",
    "    model = model_class(num_classes=num_classes)\n",
    "    state_dict = torch.load(model_path, weights_only=True)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "    \n",
    "    print(f\"Loaded model from: {model_path}\")\n",
    "    \n",
    "    # Load best parameters if present\n",
    "    best_params_path = os.path.join(model_dir, f\"{model_name}_meta.json\")\n",
    "    best_params = None\n",
    "    if os.path.exists(best_params_path):\n",
    "        with open(best_params_path, 'r') as f:\n",
    "            best_params = json.load(f)\n",
    "        # print(f\"Loaded best parameters: {best_params}\")\n",
    "    else:\n",
    "        print(\"No best_params.json found.\")\n",
    "\n",
    "    return model, best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T09:52:34.899871Z",
     "iopub.status.busy": "2025-05-15T09:52:34.899575Z",
     "iopub.status.idle": "2025-05-15T09:52:35.508186Z",
     "shell.execute_reply": "2025-05-15T09:52:35.507379Z",
     "shell.execute_reply.started": "2025-05-15T09:52:34.899850Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Evaluating the Time-domain (Gender) model on Test Set\")\n",
    "\n",
    "# Load the model\n",
    "time_model2,best_params = load_model_from_folder(TimeNet, \"time_Model\", num_classes=y_train_oh.shape[1])\n",
    "print(best_params)\n",
    "time_model2.eval()  \n",
    "\n",
    "# Evaluate\n",
    "test_time_acc_g, test_time_f1_g, test_time_cm_g, test_time_report_g = evaluate_model(time_model2, time_test_loader, y_test_oh, class_names=ohe.categories_[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T10:14:48.904721Z",
     "iopub.status.busy": "2025-05-15T10:14:48.904413Z",
     "iopub.status.idle": "2025-05-15T10:19:44.742836Z",
     "shell.execute_reply": "2025-05-15T10:19:44.742268Z",
     "shell.execute_reply.started": "2025-05-15T10:14:48.904699Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Evaluating the Mel-spectrogram (Emotion) model on Test Set\")\n",
    "\n",
    "# Load the model\n",
    "mel_model,best_params = load_model_from_folder(FreqNet, \"mal_Model\", num_classes=y_train_oh.shape[1])\n",
    "print(best_params)\n",
    "# Evaluate\n",
    "test_mel_acc, test_mel_f1, test_mel_cm, test_mel_report = evaluate_model(\n",
    "    mel_model,\n",
    "    mel_test_loader,           \n",
    "    y_test_oh,                 \n",
    "    class_names=ohe.categories_[0],\n",
    "    # pool=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-15T06:59:49.216458Z",
     "iopub.status.idle": "2025-05-15T06:59:49.216799Z",
     "shell.execute_reply": "2025-05-15T06:59:49.216620Z",
     "shell.execute_reply.started": "2025-05-15T06:59:49.216588Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# import os\n",
    "\n",
    "# model_dir = \"/kaggle/working/models/time_Model\"\n",
    "\n",
    "# if os.path.exists(model_dir):\n",
    "#     shutil.rmtree(model_dir)\n",
    "#     print(f\"Deleted folder: {model_dir}\")\n",
    "# else:\n",
    "#     print(f\"Folder not found: {model_dir}\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 1118008,
     "sourceId": 1877714,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
